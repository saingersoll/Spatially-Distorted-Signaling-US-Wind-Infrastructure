---
title: "SDS_Wind_Infrastructre"
author: "Sofia Ingersoll"
format: html
editor: visual
---

In this documentation, the data utilized is the [US Wind Data](https://dataverse.harvard.edu/file.xhtml?fileId=7339850&version=1.0), this data is associated with the "Replication Data for: Prevalence and predictors of wind energy opposition in North America", <https://doi.org/10.7910/DVN/LE2V0R>, Harvard Dataverse, V1, 2023. The collaborators on that project include: Stokes, Leah; Franzblau, Emma; Lovering, Jessica R.; Miljanich, Chris.

\~ include more about what the data is about and the outcomes of making visualization \~

Analysis of these areas will provide insight into local resistance and spatially distorted signalling in relation to wind power infrastructure and climate policy.

### Loading Libraries

The following libraries were selected based on their functionality and ability to optimize our data for mapping.

```{r, message = FALSE}
# Loading Libraries
library(tidyverse)        # essential r package 
library(sf)               # package simplifies spatial dataframes
library(cowplot)
library(spData)
library(raster)
library(ggspatial)
library(prettymapr)
library(ggmap)
library(naniar)
library(tmap)
library(terra)
library(patchwork)
library(broom)
library(stars)
library(devtools)
library(maptiles)
library(smoothr)          # aesthetic and visual aid for buffers created
```

### Read in the Data

To simplify the following step, it is important to organize your folders in a way that makes sense for your workflow. In many cases, the data sets we work with are typically too large to be uploaded to GitHub. As a result, a common practice is storing your data in a folder, directly outside of your repository in a folder labeled "data".

The code chunk below for `read.csv` demonstrates how to exit your current location using `..` and enter the desired folder location using `/`. It is important that your file path does not contain any spaces and is directly reflective of the file path for the data you wish to read in.

#### U.S. Wind Data

```{r}
# reading in & storing data
wind_data <- read.csv("../data/wind_data/wind_data_usa.csv")  
```

##### Confirm the Data Loaded Properly

```{r}
head(wind_data)                  # displays the first 6 rows of the data
                                 # along with all of the columns 
```

## Wrangling & Subsetting

### **Converting lat/long into Raster Data (i.e. sticky geometries)**

Below we will use the package `sf` to convert the lat/long data into a raster geometry column. In this single line, we will also be assigning the CRS EPSG:4326 to the sf data frame. Coordinate Reference Systems, CRS, are required in order for the data to be projected onto a map. The CRS was selected because it provides a relatively proportionate display of the United States. We are open to suggestions regarding our CRS if a different project better fits our data.

```{r}
wind_sf <- wind_data %>%             # calls desired dataset
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) 
                                     # creates geometry column with desired crs 

crs(wind_sf)                  # output should reveal WGS84, EPSG:4326
```

#### Check-point

Let's stop and see if our outputs are what we expect.

Were the lat/long columns correctly converted into a geometry column?

`setdiff()` is a way to quickly determine the differences between two data sets.

```{r}
setdiff(colnames(wind_data), colnames(wind_sf))
setdiff(colnames(wind_sf), colnames(wind_data))
```

### Initial Visualization of the Data

Using the base R function `plot()`, we can see that the geometries stored by this data set correlate to the locations of wind infrastructure plants throughout the United States. In order to visualize these locations with respect to state and county jurisdictions, we'll need to utilize another data set to create a base layer for our map.

```{r}
# First visual of the U.S. wind data provided by the geometry points
wind_plants <- ggplot(wind_sf) +
  annotation_map_tile(type = "osm") +
  geom_sf(col = 'darkgreen',
          alpha = 0.5,
          size = 3) 

wind_plants
```

# Multivariate Linear Regression Models

### Variables of Interest:

| Name       | Description                                                                                                 |
|------------------------------------|------------------------------------|
| status     | describes the operating status of wind infrastructure, binary variable. 1 is operating, 0 is not_operating. |
| pop_den    | population density of census tract ids within 3km buffer of wind infrastructure.                            |
| med_inc    | defines the median income of census tract ids within 3km buffer zone of wind infrastructure.                |
| median_age | describes the median age of census tract ids within 3 km radius of wind infrastructure.                     |

An attribute from each column will be used to run several multivariate linear regression models. This is to assess the effects of socioeconmic/regional influences on wind infrastructure and the estimated likelihood of participating legislative action when living within a 3km proximity of a wind plant.

## Determining Variable Assignments for OLS

```{r}
unique(wind_sf$status)     # displays unique values in this
```

### Need to rename status output variables

```{r}
# creating two categories: operating & not_operating
# We are removing 'Operating | Decommissioned' because it skews the data
unwanted_status <- "Operating | Decommissioned"
replacement_status <- "Uncertain Status"
wind_sf$status[wind_sf$status== unwanted_status]<-"Uncertain Status"  

# were we successful ?
unique(wind_sf$status)     # displays unique values in this

# cleaning out NAs for OLS
wind_sf <- wind_sf %>%
  filter(is.na(status) == 'FALSE') %>% 
  filter(is.na(is_anti_wind) == 'FALSE') %>% 
  filter(is.na(pop_den) == 'FALSE') %>% 
  filter(is.na(med_inc) == 'FALSE') %>% 
  filter(is.na(median_age) == 'FALSE') %>% 
  filter(is.na(n_turbs) == 'FALSE')

# were we successful ?
unique(wind_sf$status)     # displays unique values in this

# if_else preserves the data type but replaces unwanted values
wind_us <- wind_sf %>% 
  mutate(status = if_else(
    status %in% c('Cancelled', 'Out of service (temporarily)', 'Standby', 'Decommissioned', 'Uncertain Status'), 'not_operating',
    'operating') 
  )

# are our only outputs "operating" and "not_operating"?
print(unique(wind_us$status))

# status as factor and reassigned values
wind_us <- wind_us %>% 
  mutate(status = case_when(status == "operating" ~ 1,
            status == "not_operating" ~ 0))

# are our only outputs 0 or 1?
print(unique(wind_us$status))
```

Binary variable will be `status` column: `opertating` is 1, and `not_operating` will be 0.

### Initial Visualization of Categorical Response Variable

Our initial visualization demonstrates a correlation between smaller population density and wind infrastructure plants operating. This is likely associated with weight placed on voters in regions with smaller demographics. Local mobilization of minority opinion holders in these regions have a greater availabilty to push back against policymakers. However, this visual does not encapsulate all of the necessary information required to determine this with full certainty.

```{r}
# visualization of relationship
jitter_plot <- ggplot(data = wind_us, 
                      aes(x = pop_den,
                          y = status)) + 
  geom_jitter(col = 'plum',
              fill = "purple",
              width = 0,
              height = 0.05,
              alpha = 0.45,
              size = 6) +
  labs(title = "Population Density & Wind Infrastructure Activation Status",
       x = "Population Density",
       y = "Wind Infrastructure Operating Status")

jitter_plot
```

#### Logistic Regressions with Binomial Family:

#### UPDATE ALL BETAS TO MATCH NEW REGRESSIONS

$$logit(p)=log( p / 1−p)=β0+β1x+ε$$

The model that we just fit tells us that:

$$logit(p̂)=log(p̂1−p̂)=1.56−0.05847x$$

to then solve for p:

$$
p̂=e^(β0+β1x1+eβ0+β1x)
$$

Alternatively, you can solve for p using $R^2$ The `uniroot` function searches over the provided interval to find the zero value of the function provided. We pass the expression that should equal zero, and it finds us the p that ensures it equals zero.

```         
toSolve <- function(p) {(1-p)*exp(1.56-0.05847*64) - p}

uniroot(toSolve, interval = c(0, 1))$root
```

### 1 Binary Variable

$$ \text{status}\ = \beta_0 + \beta_1 \text{pop_den}\_i + \varepsilon_i $$ When wind turbines are operational, and all other variables are held constant at 0, the $\beta_0$ represents the estimated likelihood that `status` of a wind infrastructure plant is `operating` is \~ `4.48`. $\beta_1$ tells us there is an estimated decrease of `2.80` in probability that status would be `operating` for the average unit increase in `is_anti_wind` opinion holders.

Our summary table describes a null deviance `362.89`.(`1182 df`) and residual deviance `292.28` (`1181 df`). Additionally, it provides a p-value of `8.1e-15` for $\beta_1$, indicating that the hypothesis here is rejected because it is drastically smaller than the `significant value of 0.05`. However, I am still not convinced there isn't a correlation between the two, so let's explore how our numbers change as we incorporate more variables into our equation.

```{r}
# Inital regression 1 betas for null
# not a summary
status <- glm(status ~ pop_den,
                       wind_us,
                       family = 'binomial')
# summary to access coefficients
status1 <- summary(glm(status ~ pop_den,
                       wind_us,
                       family = 'binomial'))

# show me a summary table 
status1
```

### Finding P

$logit(p)=log(p/1−p)=β0+β1x+ε$

We're going to solve for a range of p values using $R^2$. We're curious about the probabilty of `operating` wind plants for Population Density at `900,000`, `26,000`, and `6,000.` UNITS!!!

```{r}
# creating a function to to describe the logistic regression model
# 100,000 
fun <- function(p) {
  (1 - p)*exp(status1$coefficients[1,'Estimate'] + (status1$coefficients[2,'Estimate']*100000)) - p
}

# 
uniroot(fun, interval = c(0,1))$root

# 26000
fun <- function(p) {
  (1 - p)*exp(status1$coefficients[1,'Estimate'] + (status1$coefficients[2,'Estimate']*26000)) - p
}

# 
uniroot(fun, interval = c(0,1))$root

# 6000
fun <- function(p) {
  (1 - p)*exp(status1$coefficients[1,'Estimate'] + (status1$coefficients[2,'Estimate']*6000)) - p
}

# 
uniroot(fun, interval = c(0,1))$root
```

### Logistic Regression Visualization

This visual is very interesting and definitely explains why the $R^2$ value is only giving values in the 0.9 range. Since our data contains a significant number of `operating` wind plants for a wide range of population densities, the regression model is producing a fit according to the `operating` status. The values in the `not_opertating` status appear to be considered similar to that of an outlier.

```{r warning = FALSE}
jitter_plot  + 
  geom_smooth(method = "lm",
              se = FALSE,
              color = 'blue') + 
  geom_smooth(method = "glm",
              se = FALSE,
              color = "hotpink",
              size = 1,
              method.args = list(family = "binomial"))
## `geom_smooth()` using formula = 'y ~ x'
## `geom_smooth()` using formula = 'y ~ x'
```

### Interpreting Coefficients Using Odds Ratio

To better interpret this relationship, we are going to change the scale of the variable on the y-axis. Now, we will be considering the odds, rather than the probability. While these two concepts are often conflated, they are not the same\[[2](https://tcarleton.github.io/EDS-222-stats/labs/06-week-six/week-6-lab-answers.html)\]. They are however, related by the simple formula below.

The **odds** of a binary event are the ratio of how often it happens, to how often it doesn't happen.

$odds(p̂)=p̂1−p̂=exp(β̂0+β̂1⋅x)$

We're going create an `odds_hat` variable for predicted odds.

That is, the ratio of the odds *after* a one unit increase in x to the odds *before*that one unit change is equal to eβ1. **Notice this doesn't depend on** x anymore! Therefore, it's a useful interpretation of coefficients.

```{r}
status_popden_predicted_odds <-  status %>%
  augment(type.predict = "response") %>%
  mutate(y_hat = .fitted) %>% 
  mutate(odds_hat = y_hat / (1 - y_hat))

status_popden_predicted_odds
```

This is an "odds ratio", meaning we care about how this number differs from 1. If it's greater than 1, then the odds increase when x increases. Conversely, if it's less than 1, then the odds decrease.

By how much does our model predict that the odds of `operating status` will change with each additional unit increase in population density?

```{r}
exp(status1$coefficients[2,'Estimate'])
```

**Answer:** Our model estimates that one unit increase in population density is associated with a change in the odds ratio of $e^(0.0001793) =1.000179$, or a 1.79e-04% increase in the odds of wind plant having an `operating` status.

### Applying a Logistic Model

Assessing Omitted Variables Bias in OLS

**words are wrong**

### OLS with 2 Variables

$$ \text{status}\ = \beta_0 + \beta_1 \text{pop_den}\_i + \beta_2 \text{med_inc} + \varepsilon_i $$ When wind turbines are operational, and all other variables are held constant at 0, the $\beta_0$ represents the estimated likelihood that status of a wind infrastructure plant is operating is \~ 4.03. $\beta_1$ tells us there is an estimated decrease of 2.47e-4 in probability that status would be operating for the average unit increase in is_anti_wind opinion holders. For every average unit increase in pop_den, $\beta_2$ predicts 1.50e-05 will increase the operating status, indicating pop_den is an extremely marginal influence, that may potentially be interacting with is_anti_wind outlook.

Our summary table describes a null deviance 362.60.(1178 df) and residual deviance 359.84 (1176 df). Additionally, it provides a p-value of 0.5 for $\beta_1$, indicating that the hypothesis here is accepted because it is greater than the significant value of 0.05. The p-value of $\beta_2$, 0.957s is acceptable because it is above range of the significant value.

```{r}
# Initial regression 2 betas for null
status2 <- summary(glm(status ~ pop_den + med_inc,
               wind_us,
               family = 'binomial'))

status2
```

#### Interpreting Coefficients using Odds Ratio

```{r}
# beta1 estimation exponentiated
exp(status2$coefficients[2,'Estimate'])
# beta2 estimation exponentiated
 1 - exp(status2$coefficients[3,'Estimate'])
```

By including the median income variable in our model and exponentiating the coefficients, we see a huge effect. Areas with an increase in population density observed an increase in their odds of having active wind infrastructure by a factor of 2.48e-04% when controlling the median income. However, the odds of operating status decrease by 1.5e-05 for each average unit increase in median income.

## Probabilistic Predictions

#\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

### OLS with 3 Variables

$$ \text{status}\ = \beta_0 + \beta_1 \text{pop_den}\_i + + \beta_2 \text{med_inc} + \beta_3 \text{median_age} + \varepsilon_i $$ When wind turbines are operational, and all other variables are held constant at 0, the $\beta_0$ represents the estimated likelihood that status of a wind infrastructure plant is operating is \~ 5.35. $\beta_1$ tells us there is an estimated decrease of 2.80 in probability that status would be operating for the average unit increase in is_anti_wind opinion holders. For every average unit increase in pop_den, $\beta_2$ predicts 1.65e-04 will increase the operating status. The dramatic change in pop_den estimated influence on status is likely due to an interaction relationship with med_inc, which intuitively makes sense. $\beta_3$ predicts 1.74e-04 will decrease the operating status, for an average unit increase in med_inc.

Our summary table describes a null deviance 362.60.(1178 df) and residual deviance 289.8 (1175 df). Additionally, it provides a p-value of 1.03e-14 for $\beta_1$, indicating that the hypothesis here is rejected because it is drastically smaller than the significant value of 0.05. The p-value of $\beta_2$, 0.668 is acceptable because it is within range of the significant value. The p-value of $\beta_3$, 0.103 is acceptable because it is within range of the significant value.

```{r}
# Regression with 3 beta
status3 <- glm(status ~ pop_den + med_inc + median_age, 
                       wind_us,
                       family = 'binomial')

summary(status3)
```

#### Interpreting Coefficients using Odds Ratio

```{r}
# beta1 estimation exponentiated
exp(status2$coefficients[2,'Estimate'])
# beta2 estimation exponentiated
 1 - exp(status2$coefficients[3,'Estimate'])
```

#\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\--

## Interpreting Omitted Variable Bias (OVB)

$\text{Null Deviance} = \text{2(LL(Saturated Model)} - \text{LL(Null Model)) on df} = \text{df_Sat - df_Null}$

[Null deviance]{.underline}: tells us how well the response variable can be predicted by a model with only an intercept term.

$\text {Residual Deviance} = \text{2(LL(Saturated Model)} - \text{LL(Proposed Model))} \text{df} = \text {df_Sat} - \text{df_Proposed}$

[Residual Deviance]{.underline}: tells us how well the response variable can be predicted by a model with p predictor variables.

$\text {The Saturated Model is a model that assumes each data point has its own parameters (which means you have n parameters to estimate.)}$

$\text {The Null Model assumes the exact "opposite", in that is assumes one parameter for all of the data points, which means you only estimate 1 parameter.}$

$\text{The Proposed Model assumes you can explain your data points with p parameters + an intercept term, so you have p+1 parameters.}$

When the **Null Deviance** is really small, it means that the Null Model explains the data pretty well. The same goes for **Residual Deviance\[[1](https://stats.stackexchange.com/questions/108995/interpreting-residual-and-null-deviance-in-glm-r)\]**. To best interpret our models, we will compare the `Residual deviance.`

### Comparing Models using anova

Comparing our 6 residual deviance outputs, models 6 and 4 produced the smallest residual deviance at `288.84` and `289.02` respectively. To determine which is the best fit, we will do an anova assessment.

```{r}
# this takes into consideration the predicted p value using both the null and residual deviation of each model and determines which more accurately describes the data
model_comparison <- anova(status6, status4, test = "Chisq") 

model_comparison
```

Our best fit OLS model is our interaction model 6: $$ \text{status}\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{pop_den} + \beta_3 \text{med_inc} + \beta_4 \text{med_age} + \varepsilon_i $$

### Constructing Confidence Interval

#### Best Fit OLS Model 6

Model 6 is restricted to 1173 degrees of freedom, as output by our earlier OLS exploration. We will apply that value when constructing our 95% Confidence Intervals.

```{r}
# Constructing a 95% confidence interval

# critical value for 2.5% quantile
c_val = qt(0.025, df = 1173, lower.tail = FALSE) %>% 
  print()

# confidence interval bounds
# since we saved our ols models as objects earlier, we can call them here

# using coef & SE from above to make 95% CI 

ci_lower <- round(status6$coefficients[2,'Estimate'] - c_val*status6$coefficients[2,'Std. Error'], 3) %>% 
  print()

ci_upper <- round(status6$coefficients[2,'Estimate'] + c_val*status6$coefficients[2,'Std. Error'], 3) %>% 
  print()

print("The first print statment refers to intercept confidence interval, and the second print statement refers to the slope CI")
print(paste0("95% probability that [", ci_lower_murder, " - ", ci_upper_murder, "] contains the difference in murder rates across the mean number of days that regions experienced frost vs no frost experience"))


#ci_lower <- round(point_est - c_val*SE, 2) %>% 
 # print()
#ci_upper <- round(point_est + c_val*SE, 2) %>% 
 # print()

# Display output
print(paste0("95% probability that interval [",ci_lower," ", ci_upper, "] contains the true difference in mean frost days between the North Central and South region."))

```

```{r}


```

### Logit

### Null Hypothesis

After considering the glm

### The null states, that the wind turbine active `status` is unimpacted by the `is_anti_wind` rating.

Two hypothesis presented are

\$H_0: \text{is_anti_wind} - \text{not_anti_wind} = 0\$

$H_A: \text{is_anti_wind} - \text{not_anti_wind} ≠ 0$

#\-\-\-\-\-\-\-\-\-\-\-\-\-\--idk

```{r}
ggplot(data= wind_us, aes(x = status, y = pop_den)) + geom_jitter(alpha=0.1, size=3) + geom_smooth(method='lm', formula= y~x, color="lightcoral", se=F, size=1.5) + theme_bw() + geom_hline(yintercept=0, color="seagreen")
```
