---
title: "SPS_Wind_Infrastructre"
author: "Sofia Ingersoll"
format: html
editor: visual
---

In this documentation, the data utilized is the [US Wind Data](https://dataverse.harvard.edu/file.xhtml?fileId=7339850&version=1.0), this data is associated with the "Replication Data for: Prevalence and predictors of wind energy opposition in North America",Â <https://doi.org/10.7910/DVN/LE2V0R>, Harvard Dataverse, V1, 2023. The collaborators on that project include: Stokes, Leah; Franzblau, Emma; Lovering, Jessica R.; Miljanich, Chris.

\~ include more about what the data is about and the outcomes of making visualization \~

Analysis of these areas will provide insight into local resistance and spatially distorted signalling in relation to wind power infrastructure and climate policy.

### Loading Libraries

The following libraries were selected based on their functionality and ability to optimize our data for mapping.

```{r, message = FALSE}
# Loading Libraries
library(tidyverse)        # essential r package 
library(sf)               # package simplifies spatial dataframes
library(raster)
library(tmap)
library(terra)
library(stars)
library(smoothr)          # aesthetic and visual aid for buffers created
```

### Read in the Data

To simplify the following step, it is important to organize your folders in a way that makes sense for your workflow. In many cases, the data sets we work with are typically too large to be uploaded to GitHub. As a result, a common practice is storing your data in a folder, directly outside of your repository in a folder labeled "data".

The code chunk below for `read.csv` demonstrates how to exit your current location using `..` and enter the desired folder location using `/`. It is important that your file path does not contain any spaces and is directly reflective of the file path for the data you wish to read in.

#### U.S. Wind Data

```{r}
# reading in & storing data
wind_data <- read.csv("../data/wind_data/wind_data_usa.csv")  
```

##### Confirm the Data Loaded Properly

```{r}
head(wind_data)                  # displays the first 6 rows of the data
                                 # along with all of the columns 
```

#### EJ Screen Data

```{r include=TRUE, eval=FALSE, warning=FALSE, error=FALSE}
ejscreen <- st_read("../data/EJSCREEN_2023_BG_StatePct_with_AS_CNMI_GU_VI.gdb",
                    quiet = TRUE)
# reads in raster data using the sf package st_read function
# the quiet T/F input refers to information output after importing data

unique(ejscreen$STATE_NAME)
# simplifying dataset
nonmapping_territories <- c('Puerto Rico', 'Guam', 'Virgin Islands', 'Northern Mariana IS', 'American Samoa', 'Northern Mariana Is')

# unionizing geometries of states to simplify plotting
us_census <- ejscreen %>% 
  filter(!STATE_NAME %in% nonmapping_territories) %>% 
  group_by(STATE_NAME)  %>% 
 summarize(geometry = st_union(Shape))

unique(us_census$STATE_NAME)
# visualizing shows still need to crop
plot(us_census)
```

**Make sure to compare the pros and cons of 3857 CRS vs 4326**

3857 is typically used in online modeling, this project is easiest to work with in this scenario.

```{r}
# this data set has a crs of 3857
crs(us_census)
```

## Wrangling & Subsetting

### **Converting lat/long into Raster Data (i.e. sticky geometries)**

Below we will use the package `sf` to convert the lat/long data into a raster geometry column. In this single line, we will also be assigning the CRS EPSG:4326 to the sf data frame. Coordinate Reference Systems, CRS, are required in order for the data to be projected onto a map. The CRS was selected because it provides a relatively proportionate display of the United States. We are open to suggestions regarding our CRS if a different project better fits our data.

```{r}
wind_sf <- wind_data %>%             # calls desired dataset
  st_as_sf(coords = c("longitude", "latitude"), crs = 3857) 
                                     # creates geometry column with desired crs 

glimpse(crs(wind_sf))                  # output should reveal WGS84, EPSG:4326
```

#### Check-point

Let's stop and see if our outputs are what we expect.

Were the lat/long columns correctly converted into a geometry column?

`setdiff()` is a way to quickly determine the differences between two data sets.

```{r}
setdiff(colnames(wind_data), colnames(wind_sf))
setdiff(colnames(wind_sf), colnames(wind_data))
```

# Initial Visualization of the Data

Using the base R function `plot()`, we can see that the geometries stored by this data set correlate to the locations of wind infrastructure plants throughout the United States. In order to visualize these locations with respect to state and county jurisdictions, we'll need to utilize another data set to create a base layer for our map.

```{r}
# First visual of the U.S. wind data provided by the geometry points
plot(wind_sf$geometry)
```

# Creating a Base Map Layer

### takes forever to load, don't run bc breaks r session

```{r}
ggplot() +
  geom_sf(data = us_census) +
  geom_sf(data = wind_us) 
```

The issue with mapping the ejscreen data is the inclusion of US territories that are not considered in the U.S. Wind Data. Many of these territories are categorized under Region Code 9. There are a couple of ways to approach this issue. Below, we will use the `st_crop` strategy to remove unwanted locations to isolate our region of interest (roi).

## Isolating Region of Interest

### Approach 1: Create a Mask using US Country Coordinates

[Geojson Coordinate Mapper for Masks](http://geojson.io/#map=2.59/42.2/-96.48)

The regions of interest within of the United States are contained within the following coordinates.

**( A helpful shortcut to fix indentation is highlighting any script and using ctrl+i )**

These coordinates were then turned into a polygon using `st_polygon` and further converted into a simple feature collection (sfc) using `st_sfc()`. The CRS of this sfc was then converted to match the map to perform the crop.

The coordinates were selected using [geojson.io](geojson%20by%20Mapbox).

Our approach to mapping the entire region of interest, we will make polygons to represent Alaska, Hawaii, and mainland United States and combine them together to make a mask. This mask will then be used to crop the EJSCREEN data, optimizing it for mapping the regions containing information on public opinions and wind power infrastructure.

#### Creating Polygons for Regions of Interest (roi)

```{r}
# creating polygons that represent our regions of interest (roi)

mainland_states <- st_polygon(     # creates a polygon with sf sticky geometries
  list(                            # stores the values as a list
    rbind(                         # binds the following coordinates into a list
      c(-127.53756028744647,       # coordinates of the polygon roi
        48.89026620120862),
      c(-127.53756028744647,
        24.9290443910311),
      c(-66.66926544935788,
        24.9290443910311),
      c(-66.66926544935788,
        48.89026620120862),
      c(-127.53756028744647,
        48.89026620120862)
    )
  )
)
mainland_states <- mainland_states %>% 
  st_sfc() %>%                         # creates a special feature collection 
  st_set_crs(3857) %>%                 # assigns a CRS that matches our data sets
  st_make_valid()                      # corrects and invalid geometries 

alaska <- st_polygon(
  list(
    rbind(
      c(-140.2228758707459,
        51.668928934953044),
      c(-140.2228758707459,
        71.43126120088658),
      c(-195.54541333159068,
        71.43126120088658),
      c( -195.54541333159068,
         51.668928934953044),
      c(-140.2228758707459,
        51.668928934953044)
    )
  )
) 
alaska <- alaska %>% 
  st_sfc() %>%                           
  st_set_crs(3857) %>%                                    
  st_make_valid()

hawaii <- st_polygon(
  list(
    rbind(
      c( -154.04703346642728,
         18.040468043330847),
      c(-154.04703346642728,
        22.729375583644853),
      c( -160.94922236072725,
         22.729375583644853),
      c(-160.94922236072725,
        18.040468043330847),
      c(-154.04703346642728,
        18.040468043330847)
    )
  )
) 
hawaii <- hawaii %>% 
  st_sfc() %>%                        
  st_set_crs(3857) %>%                                    
  st_make_valid()
```

```{r}
plot(mainland_states)
plot(alaska)
plot(hawaii)
```

```{r}
crs(mainland_states)
```

#### Making a Multipolygon

Need to transform crs to match

```{r}
mainland_alaska <- st_union(mainland_states, alaska)

states <- st_union(mainland_alaska, hawaii) %>% 
  st_set_crs("3857") %>% 
  st_make_valid()

# transforms multipolygon we created into a single polygon encompassing everything
states_bbox <- st_bbox(states) %>%
  st_as_sfc() %>% 
  st_set_crs(3857) %>% 
  st_make_valid()

glimpse(crs(states))
```

#### Check-point

If we plot our multipolygon, is it what we expect?

```{r}
plot(mainland_alaska)
plot(states)
plot(states_bbox)
```

# \* OH HELP STARTING POINT \*

-   How to work with sgbp (spatial geometry binary predicate lists)
-   Is there a more efficient way to graph ejscreen + wind_sf for checks?
-   check buffer psuedocode briefly too

#### Creating a Vectorized Mask

`st_crop`

This data did not subset properly, the output was an empty df with the proper column names

```{r}
# empty output
states_wanted <- us_census %>%
  st_filter(y = mainland_states, .predicate = st_intersects)


# output is funky sgbp, same with intersects
states_within <- st_within(us_census, states_bbox) 
#%>% 
 # diag() %>% # transforms sgbp list into vector
 # st_crop(ejscreen, states_within) 

states_logical <- lengths(states_within) > 0

states_cleaned <- us_census[states_logical, ]


# this approach provides an empty sf object
states_within2 <- ejscreen[states_bbox, op = st_within] 
# states_within3 <- ejscreen$Shape[states_bbox, op = st_within] # wrong dims

states_mask <- st_crop(ejscreen, states)

# why transforming crs here from crs = 3857?
states_mask <- states_mask %>% 
  st_transform(3857) %>% 
  st_make_valid(states_mask)
```

Another idea for subsetting relationship is `wind_sf$cen_tract_id` and `ejscreen$ID`

-   I know the dimensions are not the same, so I want to keep all the ejscreen tracts that are within the wind_sf tracts

```{r}
# dims not happy
tracts_within <- ejscreen$ID[wind_sf$cen_tract_id, op = st_within]

tracts_within2 <- st_within(ejscreen$ID, wind_sf$cen_tract_id)


```

*Preliminary Plot of Cropped EJScreen*

```{r}
plot(states_within)
```

### Approach 2: Filtering out Unwanted Region

[Region Codes](https://ncsesdata.nsf.gov/docs/location.html) reveals the various regions throughout the US that are identifiable using codes between 1:10. US Territories are categorized under the Pacific Region Code, 9. Other states like CA, OR, HA, AK, and WA are also in the Pacific Region.

```{r}
unique(ejscreen$REGION)
```

#### Identifying the State Names for US Territories

To properly filter out these unwanted observations, it's best to identify the exact names of the unwanted regions. We can do this using the `unique` function on the state_name column.

```{r}
print(unique(ejscreen$STATE_NAME))
```

#### Removing Regions Outside of Interest

**not subsetting properly, maybe use** `subset()`

%not in%

```{r}
nonmapping_territories <- c('Puerto Rico', 'Guam', 'Virgin Islands', 'Northern Mariana IS', 'American Samoa')

us_basemap_data <- ejscreen %>% 
  filter(!STATE_NAME %in% nonmapping_territories) %>% 
  filter(REGION != 10) %>% 
  group_by(STATE_NAME)

plot(us_basemap_data)
```

------------------------------------------------------------------------

Dissolve by state: ejscreen to simplify graphing: st_union(group_by state / dissolve

(USAboundaries)

```         
states %>%   group_by(group_var) %>%    summarize(geometry = st_union(geometry))
```

## Subsetting Wind Plant Locations in US

\*\* double check written description here \*\*

The code below selects only coordinates that intersect with the wind data and us mapping information

## Buffers

Buffers create polygons representing a set distance from a feature.

The buffer zone dimensions were selected to correlate with the research presented in "Replication Data for: Prevalence and predictors of wind energy opposition in North America".

**Below is psuedocode for now until the cleaning is configured right**

```{r include=TRUE}
# wind_combined <- st_union(states_mask, wind_sf)

wind_states <- st_join(states_mask, wind_sf)             # combines data sets using st_intersects 

# potentially use full_join, maybe convert into df then back to sf objects

wind_buffer <- st_buffer(wind_states$plant_name, dist = 3000) # creates a 3km buffer and dissolves                                                                   that area into a single object
# comparing the data before and after the buffers
plot(wind_combined&geometry)    
plot(wind_buffer)
```

## Randomly Selecting Addresses Within Buffer Zones

### Creating a subset containing all houses in the buffer regions

```{r}

buffer_homes <- st_within(wind_states, wind_buffer) 

print(nrow(buffer_homes), "The number of homes within buffer zones is", nrows(buffer_homes))

# or st_intersection to preserve geometries
# want to try st_within, but worry about sgbp list output
```

### Subsetting for Homes in Specific Regions

```{r}
# this is an example of how to subset for a specific roi using filtering

regional_buffer_homes <-  buffer_homes %>% 
  filter(plant_name %in% c("big windy"))
```

## Visualizing

**improperly subset, so unable to map**

```{r}
ggplot() +
  geom_sf(data = states_mask) +
  geom_sf(data = wind_sf) +
  theme_bw()
```

```{r}
ggplot() +
  geom_sf(data = states_mask) +
  geom_sf(data = wind_sf) +
  theme_bw() +
  labs(title = "US Wind Infrastructure Plants") +
annotation_scale(plot_unit = "km") +                     # add scale bar
  annotation_north_arrow(                                # add north arrow
   location = "tr",
    pad_x = unit(0.2, "in"),
    pad_y = unit(0.2, "in"),
    style = ggspatial::north_arrow_nautical(             # customize north arrow
      fill = c("grey40", "white"),
      line_col = "grey20"
    )
  )
```

### Selecting n Random Samples

```{r}
# this ensures the same random samples will be drawn when I rerun the chunk
set.seed(1)         

 # collect observations and draw a random sample
# sf object, each row is house
# group by wind turbine id - plant_n
random_sample <- buffer_homes %>%   
  #group_by() %>% 
  slice_sample(n = 1000)

# confirms 1000 rows pulled
print(dim(random_sample),'rows were randomly selected for sampling') 
```

## Multivariate Linear Regression Models

### Variables of interest:

| **Wind Infrastructure Attributes** | **Regional Attributes** | **Legislative Action** |
|------------------------------|---------------------|---------------------|
| n_turbs                            | med_inc                 | legislation_use        |
| status                             | is_anti_wind            | protesters_mean        |
| year                               | pop_den                 | courts_use             |
| total_mw                           | med_age                 | letters_use            |

An attribute from each column will be used to run several multivariate linear regression models. This is to assess the effects of socioeconmic/regional influences on wind infrastructure and the estimated likelihood of participating legislative action when living within a 3km proximity of a wind plant.

#### Determining Variable Assignments for OLS

\*\*Question - do i need to adjust these variables? I want the binary variable to be `n_turbs`. This might be redundant though because we are only evaluating houses within turbine regions. In this case, `status` may be a better indicator of SDS because it could better reflect a response as a result of public response. However, as seen below, there are 7 possible outputs for `status` . Should i re-categorize these into two categories: operating and not operating?\*\*

```{r}
unique(wind_sf$status)     # displays unique values in this column

# pseudocode
not_operating <- c('Cancelled', 'Out of service (temporarily)', 'Standby', 'Decommissioned', 'Opertaing | Decommissioned')

# assign all outputs in not_operating as "not_operating" // not working yet
wind_sf <- wind_sf %>% 
  mutate(wind_sf$status %in% not_operating == "not_operating")

unique(wind_sf$status)     # displays unique values in this column

wind_sf <- drop(wind_sf$`wind_sf$status %in% not_operating == "not_operating"`)
#$status[c('Cancelled', 'Out of service (temporarily)', 'Standby', 'Decommissioned', #'Opertaing | Decommissioned')] <- 'not_operating' 
```

Binary variable will be `status` column: `operating` will be 1, and `not_operating` will be 0.

```{r}
# where is_anti_wind is binary variable

unique(wind_sf$is_anti_wind)

# filtering out NAs just in case
wind_us <- wind_sf %>% 
  filter(is.na(is_anti_wind) == 'FALSE')

```

#### Proposed Estimation Equations:

The first four equations estimate the likelihood of taking political action when considering a regions' wind turbine status, median income, and median age.

$$ \text{status}\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{med_inc} + \beta_3 \text{med_age} + \beta_4 \text{pop_den} + \varepsilon_i $$

$$ \text{status}\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{med_inc} + \beta_3 \text{med_age} + \beta_4 \text{pop_den}+ \beta_5 \text{n_turbs} + \varepsilon_i $$

$$ \text{status}\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{legislation_use }+ \beta_3 \text{med_inc} + \beta_4 \text{med_age} + \beta_5 \text{pop_den} + \varepsilon_i $$

$$ \text{status}\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{courts_use } + \beta_3 \text{med_inc} + \beta_4 \text{med_age} + \beta_5 \text{pop_den} + \varepsilon_i $$

$$ \text{status}\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{courts_use }+ \beta_3 \text{med_inc} + \beta_4 \text{med_age} + \beta_5 \text{pop_den} + \varepsilon_i $$

$$ \text{status}\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{letters_use }+ \beta_3 \text{med_inc} + \beta_4 \text{med_age} + \beta_5 \text{pop_den} + \varepsilon_i $$

#\-\-\-\-\-\-\-- The above gml are what we should focus on & consider for our null hypothesis. It might be best to run a glm with 3 beta and then work up to 5? Maybe play around with what we input here

### GLM Linear Regressions with Binomial Family

```{r}
# Inital regression 1 betas for null
status1 <- glm(status ~ is_anti_wind ,
               random_sample,
               family = 'binomial')
glimpse(status1)

# Inital regression 2 betas for null
status2 <- glm(status ~ is_anti_wind + pop_den,
               random_sample,
               family = 'binomial')
glimpse(status2)

# Regression with 3 beta
status3 <- glm(status ~ is_anti_wind + pop_den + med_inc, 
               random_sample,
               family = 'binomial')
glimpse(status3)

# Regression with 4
status4 <- glm(status ~ is_anti_wind + pop_den + med_inc + median_age, 
               random_sample,
               family = 'binomial')
glimpse(status4)

summary(c(status1, status2, status3, status4))
```

##### Make a table of the coefficients to compare Adj R2 and interpret what the effects of each variable are

-   what adjusted r\^2 is largest and is able to estimate the largest amount of the data in the model?

-   what are the coeff. telling us about their relationship with

### Omitted Variables Bias (OVB)

By not considering `blank` as an affect on wind turbine activation status blah blah

### Null Hypothesis

After considering the glm

#### The null states, that the wind turbine active `status` is unimpacted by the `is_anti_wind` rating, regardless of population density, `pop_den`.

The `is_anti_wind` indicator of the region is more

The `status` of a wind turbine structures comparing regions with a `higher median income, median age, and lower population density`.

More simply - the is_anti_wind ratings are greater in `rural` areas compared to `urban` areas. As a result, a greater percentage of not-operating wind plants are in `rural` areas. (CALCULATE PERCENTAGE OF STATUS NOT-OPERATING & OPERATING) .

Determining the affect and relationship that anti_wind and pop_den

### The hypothesis illuminate the difference in `status OR is_anti_wind` in `rural and urban areas`

#\-\-- Should I reduce the number of variables in this to simplify my analysis?

-   Could only consider population density

-   Or income

Two hypothesis presented are

$$ H_0\ = \beta_0 + \beta_1 \text{is_anti_wind}\_i + + \beta_2 \text{med_inc} + \beta_3 \text{med_age} + \beta_4 \text{pop_den} + \varepsilon_i $$

H0: urban - rural =

### Point Estimates 

Construct a null and an alternative hypothesis that will allow you to evaluate if the birth weight of babies born to smoking mothers is different from the birth weight of babies born to non-smoking mothers.

H0:Î¼nonsmokerâÎ¼smoker=0

HA:Î¼nonsmokerâÎ¼smokerâ 0

This equation estimates the mean of the number of protesters expected when considering a regions' wind turbine status. population density, and the number of turbines.

$$ \text{protesters_mean}\ = \beta_0 + \beta_1 \text{status}\_i + + \beta_2 \text{pop_den} + \beta_3 \text{n_turbs} + \varepsilon_i $$

The final equation considers an estimation for the likelihood of a region being anti wind when assessing wind turbine status, the total mega wattage provided by the turbine, and the year the turbine was established.

$$ \text{is_anti_wind}\ = \beta_0 + \beta_1 \text{status}\_i + + \beta_2 \text{total_mw} + \beta_3 \text{year} + \varepsilon_i $$

### Assessing the relationship between proximity to wind infrastructure and political backlash

What are the estimated outcomes for randomly sampled regions within the buffer zones

##### Ex. 1: Legislation Use Estimation

When wind turbines are not operational, and all other variables are held constant, the $$\beta_0$$ represents the estimated likelihood that legislation would be utilized by the random sample roughly `amount` times. $\beta_1$ tells us the increase in probability that legislation would be used when turbines are operational. For every average unit increase in median income, $\beta_2$ predicts `amount here` will increase the use of legislation. Finally, for $$\beta_3$$ , for every average unit increase in age, a estimated `amount` is predicted to increase the use of legislation.

```{r}
legislation_est <- glm(legislation_use ~ status + med_inc + median_age,
                             random_sample,
                             family = 'binomial')
glimpse(legislation_est)
```

##### Ex. 2: Courts Use Estimation

When wind turbines are not operational, and all other variables are held constant, the $$\beta_0$$ represents the estimated likelihood that courts would be utilized by the random sample roughly `amount` times. $$\beta_1$$ tells us the increase in probability that courts would be used when turbines are operational. For every average unit increase in median income, $$\beta_2$$ predicts `amount here` will increase the use of courts. Finally, for $$\beta_3$$ , for every average unit increase in age, a estimated `amount` is predicted to increase the use of courts.

```{r}
courts_est <- glm(legislation_use ~ status + med_inc + median_age,
                             random_sample,
                             family = 'binomial')
glimpse(courts_est)
```

##### Ex. 3: Letters Use Estimation

When wind turbines are not operational, and all other variables are held constant, the $$\beta_0$$ represents the estimated likelihood that letters would be utilized by the random sample roughly `amount` times. $$\beta_1$$ tells us the increase in probability that letters would be used when turbines are operational. For every average unit increase in median income, $$\beta_2$$ predicts `amount here` will increase the use of letters. Finally, for $$\beta_3$$ , for every average unit increase in age, a estimated `amount` is predicted to increase the use of letters.

```{r}
letters_est <- glm(legislation_use ~ status + med_inc + median_age,
                             random_sample,
                             family = 'binomial')
glimpse(letters_est)
```

##### Ex. 4: Is Anti Wind Estimation

When wind turbines are not operational, and all other variables are held constant, the $$\beta_0$$ represents the estimated likelihood that people are anti wind infrastructure by the random sample roughly `amount` times. $$\beta_1$$ tells us the increase in probability the number people who are anti wind infrastructure when turbines are operational. For every average unit increase in median income, $$\beta_2$$ predicts `amount here` will increase the number of people that are anti wind infrastructure. Finally, for $$\beta_3$$ , for every average unit increase in age, a estimated `amount` is predicted to increase the number of people who are anti wind infrastructure.

```{r}
anti_wind_est <- glm(legislation_use ~ status + med_inc + median_age,
                             random_sample,
                             family = 'binomial')
glimpse(anti_wind_est)
```

##### Ex. 5: Number of Protesters Mean Estimation

When wind turbines are not operational, and all other variables are held constant, the $$\beta_0$$ represents the estimated likelihood that people are anti wind infrastructure by the random sample roughly `amount` times. $$\beta_1$$ tells us the increase in probability the number of average protesters when turbines are operational. For every average unit increase in median income, $$\beta_2$$ predicts `amount here` will increase the number of average protesters. Finally, for $$\beta_3$$ , for every average unit increase in age, a estimated `amount` is predicted to increase the number of average protesters.

```{r}
protesters_mean_est <- glm(legislation_use ~ status + pop_den + n_turbs,
                             random_sample,
                             family = 'binomial')
glimpse(protesters_mean_est)
```

#### Specific Region of Interest Estimation

##### Ex. 6: Region Is Anti Wind Estimation

When wind turbines are not operational, and all other variables are held constant, the $$\beta_0$$ represents the estimated likelihood that people are anti wind infrastructure by the random sample roughly `amount` times. $$\beta_1$$ tells us the increase in probability the number people who are anti wind infrastructure when turbines are operational. For every average unit increase in total mega wattage, $$\beta_2$$ predicts `amount here` will increase the number of people that are anti wind infrastructure. Finally, for $$\beta_3$$ , for every average unit increase in year a estimated `amount` is predicted to increase the number of people who are anti wind infrastructure.

```{r}
regional_anti_wind_est <- glm(legislation_use ~ status + total_mw + year,
                             regional_buffer_homes,
                             family = 'binomial')
glimpse(regional_anti_wind_est)
```

( maybe make a summary table of all of these estimated values and write a short synopsis )

## Interpreting Omitted Variable Bias (OVB)

Comparing the corrected $$R^2$$ values in each of the models provided below will assist in the determination of including an additional variable to our

```{r}

```

## Logit

```{r}

```

## Log Odds

```{r}

```
